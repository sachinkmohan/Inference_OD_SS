{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c60263b",
   "metadata": {},
   "source": [
    "### Load tensorRT graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b33fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load graph\n",
      "WARNING:tensorflow:From <ipython-input-1-05865e29518a>:10: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "#GRAPH_PB_PATH = './trained_models_local/saved_for_lab/tf_model_base_1502.pb'\n",
    "GRAPH_PB_PATH_OD = '../ssd_keras/converted_trt_graph/trt_graph_base_30.pb'\n",
    "#GRAPH_PB_PATH = './converted_trt_graph/trt_graph_st_prg_1601_80p.pb'\n",
    "#GRAPH_PB_PATH = './converted_trt_graph/trt_graph_quantized.pb'\n",
    "GRAPH_PB_PATH_FROZEN_SS='../segmentation_models_jetson/examples/save-pb/frozen_model_ss_plf.pb'\n",
    "\n",
    "#loading the graph for OD\n",
    "with tf.Session() as sess:\n",
    "   print(\"load graph\")\n",
    "   with gfile.FastGFile(GRAPH_PB_PATH_OD,'rb') as f:\n",
    "       graph_def1 = tf.GraphDef()\n",
    "   graph_def1.ParseFromString(f.read())\n",
    "   sess.graph.as_default()\n",
    "   tf.import_graph_def(graph_def1, name='')\n",
    "   graph_nodes1=[n for n in graph_def1.node]\n",
    "   names = []\n",
    "   for t in graph_nodes1:\n",
    "      names.append(t.name)\n",
    "\n",
    "#loading the graph for SS\n",
    "with tf.Session() as sess2:\n",
    "   print(\"load graph\")\n",
    "   with gfile.FastGFile(GRAPH_PB_PATH_FROZEN_SS,'rb') as f:\n",
    "       graph_def2 = tf.GraphDef()\n",
    "   graph_def2.ParseFromString(f.read())\n",
    "   sess.graph.as_default()\n",
    "   tf.import_graph_def(graph_def2, name='')\n",
    "   graph_nodes2=[n for n in graph_def2.node]\n",
    "   names = []\n",
    "   for t in graph_nodes2:\n",
    "      names.append(t.name)\n",
    "    # print operations\n",
    "\n",
    "   #                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af92dcc-ef75-4789-91ea-2424e0f353c0",
   "metadata": {},
   "source": [
    "### Loading the pb graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a5ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "\n",
    "tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10347122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ce17f-369e-4a8c-b70b-c212481656a5",
   "metadata": {},
   "source": [
    "### Imports for the y_decoded_pred[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316106c3-79f2-43ad-917f-1bd32a484cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/agxdbot/github/ssd_keras/')\n",
    "#goes a directory up and imports the below\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "#change the directory back to Jetson\n",
    "os.chdir('/home/agxdbot/github/Inference_OD_SS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b1299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 300, 480, 3), dtype=float32)\n",
      "Tensor(\"predictions/concat:0\", shape=(?, ?, 18), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf_input1 = tf_sess.graph.get_tensor_by_name('input_1:0')\n",
    "print(tf_input)\n",
    "tf_predictions1 = tf_sess.graph.get_tensor_by_name('predictions/concat:0')\n",
    "print(tf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1bf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_input2 = tf_sess2.graph.get_tensor_by_name('input_1:0')\n",
    "print(tf_input)\n",
    "\n",
    "tf_predictions2 = tf_sess2.graph.get_tensor_by_name('sigmoid/Sigmoid:0')\n",
    "print(tf_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63159b9-15ec-40e3-bc8d-ceec1271e89f",
   "metadata": {},
   "source": [
    "### Inference on live camera data with pb graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4207e-ea6d-4dbe-bbc6-ef57ae47c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "##Uncomment the below import if you don't want the frames to be updated on jupyter notebook or if you are using opencv frames to visualize\n",
    "#from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "\n",
    "## Drawing a bounding box around the predictions\n",
    "\n",
    "classes = ['background', 'car', 'truck', 'pedestrian', 'bicyclist', 'light'] # Just so we can print class names onto the image instead of IDs\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "  \n",
    "\n",
    "# fontScale\n",
    "fontScale = 0.5\n",
    "   \n",
    "# Blue color in BGR\n",
    "color = (255, 255, 0)\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = 1\n",
    "\n",
    "\n",
    "#Capture the video from the camera\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    #frame2 = frame.reshape((300,480))\n",
    "    image_resized2 = cv2.resize(frame, (480,300))\n",
    "    \n",
    "    image_resized3 = cv2.resize(frame, (480,320))\n",
    "\n",
    "    #print(image_resized2.shape)\n",
    "    #frame2 = np.expand_dims(image_resized2, axis=0)\n",
    "    \n",
    "    #Run the Detections using model.predict\n",
    "\n",
    "    if ret:\n",
    "        with graph.as_default():\n",
    "            set_session(sess)\n",
    "            inputs1, predictions1 = tf_sess.run([tf_input1, tf_predictions1], feed_dict={\n",
    "            tf_input: image_resized2[None, ...]\n",
    "        })\n",
    "        \n",
    "        y_pred_decoded = decode_detections(predictions1,\n",
    "                                   confidence_thresh=0.5,\n",
    "                                   iou_threshold=0.45,\n",
    "                                   top_k=200,\n",
    "                                   normalize_coords=True,\n",
    "                                   img_height=300,\n",
    "                                   img_width=480)\n",
    "        np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "        \n",
    "        for box in y_pred_decoded[0]:\n",
    "            \n",
    "            xmin = box[-4]\n",
    "            ymin = box[-3]\n",
    "            xmax = box[-2]\n",
    "            ymax = box[-1]\n",
    "            label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "            #cv2.rectangle(im2, (xmin,ymin),(xmax,ymax), color=color, thickness=2 )\n",
    "            cv2.rectangle(image_resized2, (int(xmin),int(ymin)),(int(xmax),int(ymax)), color=(0,255,0), thickness=2 )\n",
    "            cv2.putText(image_resized2, label, (int(xmin), int(ymin)), font, fontScale, color, thickness)\n",
    "        cv2.imshow('Input Images',image_resized2)\n",
    "        \n",
    "        \n",
    "        ## Semantic Segmentation Inference here\n",
    "        with graph.as_default():\n",
    "            set_session(sess)\n",
    "            inputs2, predictions2 = tf_sess2.run([tf_input2, tf_predictions2], feed_dict={\n",
    "            tf_input: image_resized3[None, ...]\n",
    "        })\n",
    "        #cv2.imwrite('file5.jpeg', 255*predictions.squeeze())\n",
    "        pred_image = 255*predictions2.squeeze()\n",
    "\n",
    "        ##converts pred_image to CV_8UC1 format so that ColorMap can be applied on it\n",
    "        u8 = pred_image.astype(np.uint8)\n",
    "\n",
    "        #Color map autumn is applied to the CV_8UC1 pred_image\n",
    "        im_color = cv2.applyColorMap(u8, cv2.COLORMAP_AUTUMN)\n",
    "        #cv2.imshow('input image', image_resized2)\n",
    "        cv2.imshow('prediction mask',im_color)\n",
    "\n",
    "        #cv2.waitKey(0)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    else:\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
